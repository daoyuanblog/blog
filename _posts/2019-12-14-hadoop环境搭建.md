---
layout: post
category : bigdata/hadoop
date: 2019-12-14
title: hadoop的环境搭建
description: 本篇文章主要简单的了解下hadoop的环境搭建
---
# 1.虚拟机的搭建
使用centos7，主要创建虚拟机镜像过程可以参考以前的文章，创建一个hadoop101的虚拟机
![](/assets/img/bigdata/hadoop/hadoop_env01.png__thumbnail) 

## 1.1关闭防火墙
进入hadoop101虚拟机，关闭防火墙，避免虚拟机之间无法访问，centos7中默认使用的是firewall防火墙，所以使用firewall命令

查看防火墙状态
````
systemctl status firewalld
````
![](/assets/img/bigdata/hadoop/hadoop_env02.png__thumbnail) 

关闭防火墙
````
systemctl stop firewalld
````
![](/assets/img/bigdata/hadoop/hadoop_env03.png__thumbnail) 

## 1.2创建一个普通用户
通过useradd 命令创建一个用户
````
useradd hadoop
````

查看创建的用户
````
ls /home/
````
![](/assets/img/bigdata/hadoop/hadoop_env04.png__thumbnail) 
创建了用户的话就会在/home目录下给该用户添加一个用户目录

删除用户
````
userdel hadoop
````
删除用户，但是创建的用户目录是不会自动删除的

给用户添加密码
````
passwd hadoop
````
表示给hadoop这个用户设置密码
![](/assets/img/bigdata/hadoop/hadoop_env05.png__thumbnail) 

## 1.3创建两个文件夹并授权给创建的用户

创建两个文件夹
````
mkdir /opt/software  /opt/module
````
software目录用来存放下载的软件, module目录用来存放安装的软件
![](/assets/img/bigdata/hadoop/hadoop_env06.png__thumbnail) 
默认创建的文件用户及用户组是root/root

给文件夹授权用户及用户组
````
chown hadoop:hadoop /opt/software /opt/module
````
上面表示给/opt下的software和module两个文件夹授权给hadoop用户组下的hadoop用户

![](/assets/img/bigdata/hadoop/hadoop_env07.png__thumbnail) 
可以看到两个文件夹的用户组和用户所有者都改成hadoop了

## 1.4将用户添加到sudoers中
有时候我们需要让普通用户又有su的权限，则需要将普通用户加入到sudoers中
````
vi /etc/sudoers
````
编辑/etc/sudoers文件，在文件中加入我们创建的普通用户  
![](/assets/img/bigdata/hadoop/hadoop_env08.png__thumbnail)   
然后通过wq!保存退出

测试普通用户添加到sudoers是否成功
通过su命令切换用户
````
su hadoop
````
![](/assets/img/bigdata/hadoop/hadoop_env09.png__thumbnail)   
输入上面的命令后，用户从root切换到hadoop了,然后就可以执行sudo相关的命令了

![](/assets/img/bigdata/hadoop/hadoop_env10.png__thumbnail)   

通过exit退出当前用户  
![](/assets/img/bigdata/hadoop/hadoop_env11.png__thumbnail)   

## 1.5更改hosts文件
配置hadoop中集群需要用到的机器地址以及别名,这样就可以直接通过别名找到对应的集群中机器的ip
````
vi /etc/hosts
````
查看主机ip为 192.168.199.238
那么我们给虚拟机可以分配为 192.168.199段的ip 比如：
````
192.168.199.100 hadoop100
192.168.199.101 hadoop101
192.168.199.102 hadoop102
192.168.199.103 hadoop103
192.168.199.104 hadoop104
192.168.199.105 hadoop105
192.168.199.106 hadoop106
192.168.199.107 hadoop107
192.168.199.108 hadoop108
192.168.199.109 hadoop109
````

可以直接通过shell脚本快速写入，创建hosts.sh文件，执行sh hosts.sh
````
#! /bin/bash
for((i=100;1<110;i++))
do
  echo "192.168.199.$i hadoop$i" >> /etc/hosts
done
````

## 1.6给虚拟机分配静态ip
分配ip的方式可以参考之前的文章，主要是让集群能够互相访问
````
vi /etc/sysconfig/network-script/ifcfg-ens33
````
![](/assets/img/bigdata/hadoop/hadoop_env12.png__thumbnail) 
## 1.7修改主机名
````
vi /etc/hostname
````

![](/assets/img/bigdata/hadoop/hadoop_env13.png__thumbnail) 

修改后通过reboot重启系统来生效  
![](/assets/img/bigdata/hadoop/hadoop_env14.png__thumbnail) 

## 1.8克隆虚拟机快照
将我们上面创建的hadoop100虚拟机作为最基本的虚拟机，而接下来我们需要建立虚拟机快照，在这些快照的虚拟机中进行操作，这个就跟docker中的layer一样，每次新的操作都是在新的layer中进行操作，从而不影响最基本的虚拟机

![](/assets/img/bigdata/hadoop/hadoop_env15.png__thumbnail) 

创建完整的克隆  表示直接克隆一份跟原来虚拟机一样大的虚拟机，这样占用的物理磁盘特别大，而使用创建连接克隆的话，只需要一小部分物理磁盘即可，记住： 克隆虚拟机的时候，目标虚拟机一定要关闭后，才能进行克隆，不如克隆的虚拟机会处于目标虚拟机一样的状态

下面创建一个连接克隆，按照上面的步骤分配一个网络ip和修改主机名，因为是克隆处的虚拟机，所以之前的配置都在，比如之前创建的用户，ip，主机名，所以我们只需要修改主机名和ip地址即可快速分配一台新的虚拟机
![](/assets/img/bigdata/hadoop/hadoop_env16.png__thumbnail) 

![](/assets/img/bigdata/hadoop/hadoop_env17.png__thumbnail) 

# 2.jdk和hadoop软件的安装
在前面创建的目录/opt/software中通过wget命令下载jdk和hadoop安装包
## 2.1jdk的安装

### 2.1.1检查是否已安装过jdk
java -version
如果有输出则表示系统已自动安装，则可以通过rpm 命令来卸载

### 2.1.2下载jdk
jdk的下载地址可以到oracle官网去获取,目前jdk的下载需要权限，所以以下地址可能会失效，需要重新到oracle官网去下载
````
wget https://download.oracle.com/otn/java/jdk/8u231-b11/5b13a193868b4bf28bcb45c792fce896/jdk-8u231-linux-x64.tar.gz?AuthParam=1576020023_fdb875c66d3351ccd6e2a9619260f1ba
````
![](/assets/img/bigdata/hadoop/hadoop_env18.png__thumbnail) 

### 2.1.3解压安装jdk
将上面下载的jdk解压到指定的module目录
````
tar -xvf jdk-8u231-linux-x64.tar.gz -C /opt/module/
````
![](/assets/img/bigdata/hadoop/hadoop_env19.png__thumbnail) 

### 2.1.4配置jdk环境变量
因为我们使用的是hadoop普通用户权限，编译/etc/profile是需要管理员权限的，所以需要使用sudo来执行管理员权限(前提是将hadoop加入了suders文件中)
````
sudo vim /etc/profile
````

设置jdk环境变量，并添加到系统PATH中，再通过export将变量设置为全局变量
````
#JAVA_HOME
JAVA_HOME=/opt/module/jdk1.8.0_231
export JAVA_HOME


PATH=$PATH:$JAVA_HOME/bin
export PATH
````
上面先定义一个JAVA_HOME局部变量，并通过export将JAVA_HOME设置为系统全局变量，然后定义一个局部变量PATH并引用全局变量，然后再通过export将PATH设置为系统全局变量

修改完系统配置文件后，一定要使其生效，通过source命令重新加载，不用重启系统
````
source /etc/profile
````

检查环境变量是否设置正常
````
echo $JAVA_HOME
````
![](/assets/img/bigdata/hadoop/hadoop_env20.png__thumbnail) 

### 2.1.5检查jdk是否安装正确
````
java -version
````
![](/assets/img/bigdata/hadoop/hadoop_env21.png__thumbnail) 
命令正确输出，且jdk版本跟安装的一致，则表示安装正确

## 2.2hadoop的安装
### 2.2.1下载hadoop
hadoop可以直接在apache官网去下载
````
wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.10.0/hadoop-2.10.0.tar.gz
````

![](/assets/img/bigdata/hadoop/hadoop_env22.png__thumbnail) 

### 2.2.2解压安装hadoop
````
tar -xvf /opt/software/hadoop-2.10.0.tar.gz -C /opt/module/
````
![](/assets/img/bigdata/hadoop/hadoop_env23.png__thumbnail) 

### 2.2.3配置hadoop环境变量
hadoop需要配置地址到PATH中,hadoop/bin和hadoop/sbin 一个是hadoop的命令,另一个是hadoop的shell脚本命令
````
sudo vim /etc/profile
````
设置hadoop的变量到PATH中
````
#HADOOP_HOME
HADOOP_HOME=/opt/module/hadoop-2.10.0
export HADOOP_HOME

PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
````
设置完通过source /etc/profile让配置生效
````
source /etc/profile
````

检查环境变量设置是否生效
````
echo $HADOOP_HOME
````
![](/assets/img/bigdata/hadoop/hadoop_env24.png__thumbnail) 

### 2.2.4检查hadoop是否安装成功
````
hadoop version
````
![](/assets/img/bigdata/hadoop/hadoop_env25.png__thumbnail) 
输出以上信息表示hadoop安装并配置环境变量成功





